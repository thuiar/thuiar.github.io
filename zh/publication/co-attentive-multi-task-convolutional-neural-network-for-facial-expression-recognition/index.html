<!DOCTYPE html><html lang="zh-Hans" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="徐华">

  
  
  
    
  
  <meta name="description" content="Previous research on Facial Expression Recognition (FER) assisted by facial landmarks mainly focused on single-task learning or hard-parameter sharing based multi-task learning. However, soft-parameter shar- ing based methods have not been explored in this area. Therefore, this paper adopts Facial Landmark Detection (FLD) as the auxiliary task and explores new multi-task learning strategies for FER. First, three classical multi-task structures, including Hard-Parameter Sharing (HPS), Cross-Stitch Network (CSN), and Partially Shared Multi-task Convolutional Neural Network (PS-MCNN), are used to verify the advantages of multi-task learning for FER. Then, we propose a new end-to-end Co-attentive Multi-task Convolutional Neural Network (CMCNN), which is composed of the Channel Co-Attention Module (CCAM) and the Spa- tial Co-Attention Module (SCAM). Functionally, the CCAM generates the channel co-attention scores by capturing the inter-dependencies of different channels between FER and FLD tasks. The SCAM combines the max- and average-pooling operations to formulate the spatial co-attention scores. Finally, we con- duct extensive experiments on four widely used benchmark facial expression databases, including RAF, SFEW2, CK&#43;, and Oulu-CASIA. Extensive experimental results show that our approach achieves better performance than single-task and multi-task baselines, fully validating multi-task learning s effectiveness and generalizability.">

  
  <link rel="alternate" hreflang="en" href="https://thuiar.github.io/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/">
  
  <link rel="alternate" hreflang="zh-Hans" href="https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/zh/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_huf9441868456af88e4429501459a79a2b_153180_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_huf9441868456af88e4429501459a79a2b_153180_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="清华大学IAR研究组">
  <meta property="og:url" content="https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/">
  <meta property="og:title" content="Co-attentive multi-task convolutional neural network for facial expression recognition | 清华大学IAR研究组">
  <meta property="og:description" content="Previous research on Facial Expression Recognition (FER) assisted by facial landmarks mainly focused on single-task learning or hard-parameter sharing based multi-task learning. However, soft-parameter shar- ing based methods have not been explored in this area. Therefore, this paper adopts Facial Landmark Detection (FLD) as the auxiliary task and explores new multi-task learning strategies for FER. First, three classical multi-task structures, including Hard-Parameter Sharing (HPS), Cross-Stitch Network (CSN), and Partially Shared Multi-task Convolutional Neural Network (PS-MCNN), are used to verify the advantages of multi-task learning for FER. Then, we propose a new end-to-end Co-attentive Multi-task Convolutional Neural Network (CMCNN), which is composed of the Channel Co-Attention Module (CCAM) and the Spa- tial Co-Attention Module (SCAM). Functionally, the CCAM generates the channel co-attention scores by capturing the inter-dependencies of different channels between FER and FLD tasks. The SCAM combines the max- and average-pooling operations to formulate the spatial co-attention scores. Finally, we con- duct extensive experiments on four widely used benchmark facial expression databases, including RAF, SFEW2, CK&#43;, and Oulu-CASIA. Extensive experimental results show that our approach achieves better performance than single-task and multi-task baselines, fully validating multi-task learning s effectiveness and generalizability."><meta property="og:image" content="https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/featured.png">
  <meta property="twitter:image" content="https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/featured.png"><meta property="og:locale" content="zh-Hans">
  
    
      <meta property="article:published_time" content="2021-11-01T16:24:04&#43;08:00">
    
    <meta property="article:modified_time" content="2021-11-01T16:24:04&#43;08:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/"
  },
  "headline": "Co-attentive multi-task convolutional neural network for facial expression recognition",
  
  "image": [
    "https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/featured.png"
  ],
  
  "datePublished": "2021-11-01T16:24:04+08:00",
  "dateModified": "2021-11-01T16:24:04+08:00",
  
  "author": {
    "@type": "Person",
    "name": "余文梦"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "清华大学IAR研究组",
    "logo": {
      "@type": "ImageObject",
      "url": "https://thuiar.github.io/images/icon_huf9441868456af88e4429501459a79a2b_153180_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Previous research on Facial Expression Recognition (FER) assisted by facial landmarks mainly focused on single-task learning or hard-parameter sharing based multi-task learning. However, soft-parameter shar- ing based methods have not been explored in this area. Therefore, this paper adopts Facial Landmark Detection (FLD) as the auxiliary task and explores new multi-task learning strategies for FER. First, three classical multi-task structures, including Hard-Parameter Sharing (HPS), Cross-Stitch Network (CSN), and Partially Shared Multi-task Convolutional Neural Network (PS-MCNN), are used to verify the advantages of multi-task learning for FER. Then, we propose a new end-to-end Co-attentive Multi-task Convolutional Neural Network (CMCNN), which is composed of the Channel Co-Attention Module (CCAM) and the Spa- tial Co-Attention Module (SCAM). Functionally, the CCAM generates the channel co-attention scores by capturing the inter-dependencies of different channels between FER and FLD tasks. The SCAM combines the max- and average-pooling operations to formulate the spatial co-attention scores. Finally, we con- duct extensive experiments on four widely used benchmark facial expression databases, including RAF, SFEW2, CK+, and Oulu-CASIA. Extensive experimental results show that our approach achieves better performance than single-task and multi-task baselines, fully validating multi-task learning s effectiveness and generalizability."
}
</script>

  

  


  


  





  <title>Co-attentive multi-task convolutional neural network for facial expression recognition | 清华大学IAR研究组</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
    <script>window.staDarkLightChooser = true;</script>
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="/js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>搜索</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="搜索..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/zh/">清华大学IAR研究组</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="切换导航">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/zh/">清华大学IAR研究组</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#hero"><span>主页</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#direction"><span>主研方向</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#people"><span>成员</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#patents"><span>专利</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#courses"><span>主讲课程</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#textbooks"><span>教材</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#monographs"><span>专著</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#accomplishments"><span>奖项</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/paper_list/index.html"><span>论文和共享资源</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/zh/#contact"><span>联系</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="搜索"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>浅色</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>深色</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>自动</span>
          </a>
        </div>
      </li>
      

      
      <li class="nav-item dropdown i18n-dropdown">
        <a href="#" class="nav-link " data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-globe mr-1" aria-hidden="true"></i></a>
        <div class="dropdown-menu">
          <div class="dropdown-item dropdown-item-active">
            <span>中文 (简体)</span>
          </div>
          
          <a class="dropdown-item" href="https://thuiar.github.io/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/">
            <span>English</span>
          </a>
          
        </div>
      </li>
      

    </ul>

  </div>
</nav>



  <div class="pub">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Co-attentive multi-task convolutional neural network for facial expression recognition</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span ><a href="/zh/author/%E4%BD%99%E6%96%87%E6%A2%A6/">余文梦</a></span>, <span ><a href="/zh/author/%E5%BE%90%E5%8D%8E/">徐华</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    November 2021
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  
    
  



<a class="btn btn-outline-primary my-1 mr-1" href="https://doi.org/10.1016/j.patcog.2021.108401" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1" href="https://github.com/thuiar/cmcnn" target="_blank" rel="noopener">
  代码
</a>












<a class="btn btn-outline-primary my-1 mr-1" href="https://doi.org/10.1016/j.patcog.2021.108401" target="_blank" rel="noopener">
  DOI
</a>



</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 389px;">
  <div style="position: relative">
    <img src="/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/featured_huaea541f4fa075c2e96be98210eb2e225_212158_720x0_resize_lanczos_3.png" alt="" class="featured-image">
    
  </div>
</div>



  <div class="article-container">

    
    <h3>摘要</h3>
    <p class="pub-abstract">Previous research on Facial Expression Recognition (FER) assisted by facial landmarks mainly focused on single-task learning or hard-parameter sharing based multi-task learning. However, soft-parameter shar- ing based methods have not been explored in this area. Therefore, this paper adopts Facial Landmark Detection (FLD) as the auxiliary task and explores new multi-task learning strategies for FER. First, three classical multi-task structures, including Hard-Parameter Sharing (HPS), Cross-Stitch Network (CSN), and Partially Shared Multi-task Convolutional Neural Network (PS-MCNN), are used to verify the advantages of multi-task learning for FER. Then, we propose a new end-to-end Co-attentive Multi-task Convolutional Neural Network (CMCNN), which is composed of the Channel Co-Attention Module (CCAM) and the Spa- tial Co-Attention Module (SCAM). Functionally, the CCAM generates the channel co-attention scores by capturing the inter-dependencies of different channels between FER and FLD tasks. The SCAM combines the max- and average-pooling operations to formulate the spatial co-attention scores. Finally, we con- duct extensive experiments on four widely used benchmark facial expression databases, including RAF, SFEW2, CK+, and Oulu-CASIA. Extensive experimental results show that our approach achieves better performance than single-task and multi-task baselines, fully validating multi-task learning s effectiveness and generalizability.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">类型</div>
          <div class="col-12 col-md-9">
            
            
            <a href="/zh/publication/#2">
              期刊文章
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">出版物</div>
          <div class="col-12 col-md-9">Pattern Recognition</div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"></div>

    








<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/&amp;text=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/&amp;t=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition&amp;body=https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/&amp;title=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition%20https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://thuiar.github.io/zh/publication/co-attentive-multi-task-convolutional-neural-network-for-facial-expression-recognition/&amp;title=Co-attentive%20multi-task%20convolutional%20neural%20network%20for%20facial%20expression%20recognition" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  
    
    
    
    
    
    <div class="media author-card content-widget-hr">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/zh/author/%E4%BD%99%E6%96%87%E6%A2%A6/">余文梦</a></h5>
        <h6 class="card-subtitle">硕士</h6>
        <p class="card-text">我的研究方向为多模态学习、人脸表情识别、多任务学习。</p>
        <ul class="network-icon" aria-hidden="true">
  
</ul>

      </div>
    </div>
  


  
    
    





  
    
    
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/zh/author/%E5%BE%90%E5%8D%8E/avatar_hufc278e4127e99d69dc26cf1bf97fa481_942706_270x270_fill_q90_lanczos_center.jpg" alt="徐华">
      

      <div class="media-body">
        <h5 class="card-title"><a href="/zh/author/%E5%BE%90%E5%8D%8E/">徐华</a></h5>
        <h6 class="card-subtitle">长聘副教授, Expert Systems with Application 副主编，博士生导师</h6>
        
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:xuhua@mail.tsinghua.edu.cn" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  


  












  
  





  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/highlight.min.js" integrity="sha512-7t8APmYpzEsZP7CYoA7RfMPV9Bb+PJHa9x2WiUnDXZx3XHveuyWUtvNOexhkierl5flZ3tr92dP1mMS+SGlD+A==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.2/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/zh/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"没有找到结果","placeholder":"搜索...","results":"搜索结果"};
      const content_type = {
        'post': "文章",
        'project': "项目",
        'publication' : "出版物",
        'talk' : "演讲",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.f6ecf7692215f2bc4850b72c8176bfa2.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    © THUIAR 2024
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://wowchemy.com" target="_blank" rel="noopener">Wowchemy Website Builder</a>
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">引用</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> 复制
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> 下载
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
